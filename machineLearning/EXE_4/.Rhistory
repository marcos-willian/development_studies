#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
#treinando modelo
svmTreinamento = ksvm(espiralTreinamento$x,
espiralTreinamento$classes,
type = "C-bsvc",
kernel = "rbfdot",
kpar = list(sigma = 0.5),
C = 5)
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
countour(svmTreinamento@SVindex)
contour(svmTreinamento@SVindex)
contour(espiralTreinamento$x[svmTreinamento@SVindex,])
predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
x = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
length(x)
espiralTeste$x
espiralTeste$x
cl
espiralTeste$classes
x
x = espiralTeste$classes
x = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
x == espiralTeste$classes
contour(espiralTreinamento$x)
#Os dados de treinamento gerados plotados
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Dados de treinamento")
#Plotando os dados de teste
plot(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
#Plotando os dados de teste
points(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
#Os dados de treinamento gerados plotados
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Dados de treinamento")
#Plotando os dados de teste
points(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
svmTreinamento@alpha[[1]]
x =svmTreinamento@alpha[[1]]
alpha(svmTreinamento)
View(svmTreinamento)
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
data(spirals)
plot(spirals)
plot(svmTreinamento, data=NULL, grid = 50, slice = list())
plot(svmTreinamento, data=NULL, grid = 50, slice = list())
plot(svmTreinamento, data=NULL, grid = 50, )
plot(svmTreinamento, data=NULL, grid = 50)
#treinando modelo
svmTreinamento = ksvm(espiralTreinamento$x,
espiralTreinamento$classes,
type = "C-bsvc",
kernel = "rbfdot",
kpar = list(sigma = 0.5),
C = 5)
plot(svmTreinamento, data=NULL, grid = 50)
x <- rbind(matrix(rnorm(120),,2),matrix(rnorm(120,mean=3),,2))
y <- matrix(c(rep(1,60),rep(-1,60)))
svp <- ksvm(x,y,type="C-svc")
plot(svp,data=x)
plot(x)
plot(x, col = cores[y])
View(y)
plot(x, col = cores[y+2])
#Variaveis gerais
cores = c("red", "blue", "green")
plot(x, col = cores[y+2])
x <- rbind(matrix(rnorm(120),,2),matrix(rnorm(120,mean=3),,2))
y <- matrix(c(rep(1,60),rep(-1,60)))
svp <- ksvm(x,y,type="C-svc")
plot(svp,data=x)
plot(svmTreinamento, data=espiralTreinamento$x, grid = 50)
x <- rbind(matrix(rnorm(120),,2),matrix(rnorm(120,mean=3),,2))
y <- matrix(c(rep(1,60),rep(-1,60)))
svp <- ksvm(x,y,type="C-bsvc")
plot(svp,data=x)
contour(svmTreinamento)
contour(espiralTeste)
contour(espiralTeste$x)
contour(espiralTeste$x,espiralTeste$classes)
contour(espiralTeste$x,espiralTeste$classes)
contour(cbind(espiralTeste$x,espiralTeste$classes)
)
#Plotando os dados de teste
plot(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
svm <- ksvm(xin, yin, type = "C-svc", kernel = "rbfdot", kpar = list(sigma = 0.1), C = 10)
yhat = predict(svm,xin, type = "response")
#treinando modelo
svmTreinamento = ksvm(espiralTreinamento$x,
espiralTreinamento$classes,
type = "C-svc",
kernel = "rbfdot",
kpar = list(sigma = 0.5),
C = 5)
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
contour(espiralTreinamento$x[svmTreinamento@SVindex,])
x = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
plot(svmTreinamento, data=espiralTreinamento$x, grid = 50)
#Os dados de treinamento gerados plotados
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Dados de treinamento")
#treinando modelo
svmTreinamento = ksvm(espiralTreinamento$x,
espiralTreinamento$classes,
type = "C-bsvc",
kernel = "rbfdot",
kpar = list(sigma = 0.5),
C = 5)
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
contour(espiralTreinamento$x[svmTreinamento@SVindex,])
x = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
plot(svmTreinamento, data=espiralTreinamento$x, grid = 50)
plot_svm_jk(espiralTreinamento$x)
install.packages("remotes")
remotes::install_github("ExabytE1337/Lori")
plot_svm_jk(espiralTreinamento$x)
library("ExabyE1337/Lori")
library("ExabytE1337/Lori")
plot_svm_jk(espiralTreinamento$x)
svmTreinamento@alpha[[1]]*espiralTreinamento$x[svmTreinamento@SVindex,]
espiralTreinamento$x[svmTreinamento@SVindex,]*espiralTreinamento$x[svmTreinamento@SVindex,]
x = c(1,2,3)
y = T(x)
y = t(x)
x
y
y * x
y %*% x
x %*% x
sqrt(14)
norm(x)
|x|
espiralTreinamento$x[svmTreinamento@SVindex,]*espiralTreinamento$x[svmTreinamento@SVindex,]
espiralTreinamento$x[svmTreinamento@SVindex,]%*%espiralTreinamento$x[svmTreinamento@SVindex,]
rm(list =  ls())
library("kernlab")
xc1 = replicate(2, rnorm(50) + 4)
xc2 = replicate(2, rnorm(50) + 2)
xin = rbind(xc1,xc2)
yin = rbind(matrix(-1,50,1), matrix(1,50,1))
plot(xc1, col = "red", type = "p", xlim = c(0,6), ylim = c(0,6))
points(xc2, col = "blue")
svm <- ksvm(xin, yin, type = "C-bsvc", kernel = "rbfdot", kpar = list(sigma = 0.1), C = 10)
yhat = predict(svm,xin, type = "response")
a = alpha(svm)
ai = SVindex(svm)
nsvec = svm@nSV
points(xin[ai,], col = "green")
plot(yhat)
contour(yhat)
contour(xin,yhat)
contour(svmTreinamento)
rm(list =  ls())
library("kernlab")
library("mlbench")
data(spirals)
plot(spirals)
#Variaveis gerais
cores = c("red", "blue", "green")
#Criando 600 amostras de treinamento
espiralTreinamento<-mlbench.spirals(600,1,0.05)
#Criando 200 amostras para teste
espiralTeste<-mlbench.spirals(200,1,0.05)
#Os dados de treinamento gerados plotados
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Dados de treinamento")
#Plotando os dados de teste
plot(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
#treinando modelo
svmTreinamento = ksvm(espiralTreinamento$x,
espiralTreinamento$classes,
type = "C-bsvc",
kernel = "rbfdot",
kpar = list(sigma = 0.5),
C = 5)
#Plota os vetores de suporte
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Vetores de suporte (verde)")
points(espiralTreinamento$x[svmTreinamento@SVindex,], col = "green")
contour(svmTreinamento)
contour(svmTreinamento@alpha)
grid = matrix(seq(from = 1, to = 3, length.out = 8), seq(from = 1, to = 3, length.out = 8))
plot(grid)
View(grid)
grid = matrix(seq(from = 1, to = 3, length.out = 3), nrow = 2)
grid = matrix(seq(from = 1, to = 3, length.out = 4), nrow = 2)
?expand.grid
expand.grid(xgrid)
xgrid = seq(from = 1, to = 3, length.out = 4)
xgrid = seq(from = 1, to = 3, length.out = 4)
expand.grid(xgrid)
?range
range(x)
range(xgrid)
range(espiralTreinamento$x)
range(espiralTreinamento$c(-1,1))
range(c(-1,1))
rbind(c(-1,1),c(-1,1))
apply(rbind(c(-1,1),c(-1,1)), 2, range)
apply(cbind(c(-1,1),c(-1,1)), 2, range)
apply(cbind(c(-1,2,1),c(-1,2,1)), 2, range)
apply(cbind(c(-1,245,1),c(-1,2,1)), 2, range)
grange = apply(rbind(c(-1,1),c(-1,1)), 2, range)
x1 = seq(from = grange[1,1], to = grange[2,1], length = n)
n = 75
x1 = seq(from = grange[1,1], to = grange[2,1], length = n)
x1
grange = apply(rbind(c(1,1),c(-1,1)), 2, range)
grange = apply(rbind(c(1,1),c(-1,-1)), 2, range)
x1 = seq(from = grange[1,1], to = grange[2,1], length = n)
x1
x2 = seq(from = grange[1,2], to = grange[2,2], length = n)
x2
expand.grid(X1 = x1, X2 = x2)
expand.grid(X1 = x1)
expand.grid(x1)
expand.grid(x1)
?expand.grid
expand.grid(X1 = xGrid, X2 = xGrid)
xGrid = seq(from = -1, to = 1, length = n)
expand.grid(X1 = xGrid, X2 = xGrid)
plot(expand.grid(X1 = xGrid, X2 = xGrid))
n = 50
xGrid = seq(from = -1, to = 1, length = n)
plot(expand.grid(X1 = xGrid, X2 = xGrid))
?plot
?points
plot(expand.grid(X1 = xGrid, X2 = xGrid), pch = 20)
plot(grid, pch = 20)
grid = expand.grid(X1 = xGrid, X2 = xGrid)
plot(grid, pch = 20)
margin = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
length(margin)
decisionSurface = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
plot(grid, col = decisionSurface, pch = 20)
contour(grid, decisionSurface)
grid[1,]
grid[,2]
contour(grid[,1], grid[,2], decisionSurface)
contour(grid, ecisionSurface)
contour(grid, decisionSurface)
decisionSurface
=
plot(grid, col = decisionSurface, pch = 20)
contour(cbind(grid,decisionSurface))
?contour
contour(x = grid[,1], y = grid[,2], z = decisionSurface)
grid[,1]
grid[,2]
require(grDevices) # for colours
x <- -6:16
op <- par(mfrow = c(2, 2))
contour(outer(x, x), method = "edge", vfont = c("sans serif", "plain"))
z <- outer(x, sqrt(abs(x)), FUN = "/")
image(x, x, z)
contour(x, x, z, col = "pink", add = TRUE, method = "edge",
vfont = c("sans serif", "plain"))
contour(x, x, z, ylim = c(1, 6), method = "simple", labcex = 1,
xlab = quote(x[1]), ylab = quote(x[2]))
contour(x, x, z, ylim = c(-6, 6), nlevels = 20, lty = 2, method = "simple",
main = "20 levels; \"simple\" labelling method")
par(op)
x = seq(0, 1, length.out = 25)
x
contour(x = xGrid, y = xGrid, z = decisionSurface)
decisionSurface
decisionSurface == 1
contour(x = xGrid, y = xGrid, z = decisionSurface == 1)
contour(x = xGrid, y = xGrid, z = as.matrix(decisionSurface)
contour(x = xGrid, y = xGrid, z = as.matrix(decisionSurface))
contour(x = xGrid, y = xGrid, z = as.matrix(decisionSurface))
contour(xGrid, xGrid, matrix(decisionSurface, 69, 99), level = 0, add = TRUE)
contour(xGrid, xGrid, matrix(decisionSurface, 50, 50), level = 0, add = TRUE)
contour(xGrid, xGrid, matrix(decisionSurface, 50, 50), level = 0, add = TRUE)
contour(xGrid, xGrid, matrix(decisionSurface, 50, 50), level = 0)
contour(xGrid, xGrid, matrix(decisionSurface == 1, 50, 50), level = 0)
matrix(decisionSurface == 1, 50, 50)
50*50
contour(xGrid, xGrid, matrix(decisionSurface == 1, 50, 50))
contour(xGrid, xGrid, matrix(decisionSurface , 50, 50))
#Plota superficie de decisão
n = 100
xGrid = seq(from = -1, to = 1, length = n)
grid = expand.grid(X1 = xGrid, X2 = xGrid)
decisionSurface = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
contour(xGrid, xGrid, matrix(decisionSurface , n, n))
#Plota superficie de decisão
n = 200
xGrid = seq(from = -1, to = 1, length = n)
grid = expand.grid(X1 = xGrid, X2 = xGrid)
decisionSurface = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
contour(xGrid, xGrid, matrix(decisionSurface , n, n))
#Plota superficie de decisão
n = 500
xGrid = seq(from = -1, to = 1, length = n)
grid = expand.grid(X1 = xGrid, X2 = xGrid)
decisionSurface = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
contour(xGrid, xGrid, matrix(decisionSurface , n, n))
decisionSurface = predict(svmTreinamento, grid, type = "response", coupler = "minpair")
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Contorno de separação das classes")
contour(xGrid, xGrid, matrix(decisionSurface , n, n), add = TRUE)
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Contorno de separação das classes")
contour(xGrid, xGrid, matrix(decisionSurface , n, n), add = TRUE, level = 1)
contour(xGrid, xGrid, matrix(decisionSurface , n, n), add = TRUE, levels = 1)
contour(xGrid, xGrid, matrix(decisionSurface , n, n), add = TRUE)
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Contorno de separação das classes")
contour(xGrid, xGrid, matrix(decisionSurface , n, n), add = TRUE, drawlabels = FALSE)
#Plota superficie de separação
persp3D(seqi,seqj,M1,counter=T,theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
library("plot3D")
install.packages("plot3D")
library("plot3D")
#Plota superficie de separação
persp3D(seqi,seqj,M1,counter=T,theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface, counter=T, theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface, counter=T, theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
?persp3D
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface)
decisionSurface = matrix(predict(svmTreinamento, grid, type = "response", coupler = "minpair"), n, n)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface, counter=T, theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
plot(espiralTreinamento$x, col = cores[espiralTreinamento$classes],
xlab = "X", ylab = "Y", main = "Contorno de separação das classes")
contour(xGrid, xGrid, decisionSurface, add = TRUE, drawlabels = FALSE)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface, counter=T, theta = 55, phi = 30, r = 40, d = 0.1,
expand = 0.5, ltheta = 90, lphi = 180, shade = 0.4, ticktype = "detailed",
nticks=5)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface)
#Plota superficie de separação
persp3D(decisionSurface)
#Plota superficie de separação
persp3D(xGrid, decisionSurface)
, xGrid,
#Plota superficie de separação
persp3D(xGrid, xGrid,decisionSurface)
View(decisionSurface)
x = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
#Plota superficie de separação
persp3D(xGrid, xGrid,decisionSurface[,])
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX4/RCode/EX3.R", encoding = 'UTF-8')
#Teste do modelo
x <- seq(-10, 10, length = 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2 + y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
View(f)
z[is.na(z)] <- 1
persp3d(x, y, z, aspect = c(1, 1, 0.5), col = "lightblue",
xlab = "X", ylab = "Y", zlab = "Sinc( r )",
polygon_offset = 1)
library("plot3D")
persp3d(x, y, z, aspect = c(1, 1, 0.5), col = "lightblue",
xlab = "X", ylab = "Y", zlab = "Sinc( r )",
polygon_offset = 1)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface[,])
#Plota superficie de separação
persp3d(xGrid, xGrid, decisionSurface[,])
persp3D(x, y, z, aspect = c(1, 1, 0.5), col = "lightblue",
xlab = "X", ylab = "Y", zlab = "Sinc( r )",
polygon_offset = 1)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface[,])
str(decisionSurface)
is.numeric(decisionSurface)
is.character(decisionSurface)
decisionSurface = as.mumeric(matrix(predict(svmTreinamento, grid, type = "response", coupler = "minpair"), n, n))
decisionSurface = matrix(predict(svmTreinamento, grid, type = "response", coupler = "minpair"), n, n)
decisionSurface = matrix(predict(svmTreinamento, grid, type = "response"), n, n)
decisionSurface = predict(svmTreinamento, grid, type = "response")
decisionSurface = matrix(as.numeric(predict(svmTreinamento, grid, type = "response")), n, n)
is.numeric(decisionSurface)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 0.1,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed",
nticks=5)
persp3D
?persp3D
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 0.1,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed")
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 0.1,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed",
nticks=3)
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 0.1,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed",
nticks=3,
main = "Superfície de separação")
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 0.5,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed",
nticks=3,
main = "Superfície de separação")
#Plota superficie de separação
persp3D(xGrid, xGrid, decisionSurface,
counter=T,
theta = 55,
phi = 30,
r = 40,
d = 5,
expand = 0.5,
ltheta = 90,
lphi = 180,
shade = 0.4,
ticktype = "detailed",
nticks=3,
main = "Superfície de separação")
#Teste do modelo
#Plotando os dados de teste
plot(espiralTeste$x, xlab = "X", ylab = "Y", main = "Dados de teste")
#Classifica amostras
classesTeste = predict(svmTreinamento, espiralTeste$x, type = "response", coupler = "minpair")
#Plota o resultado da classificação
plot(espiralTeste$x,
col = cores[classesTeste],
xlab = "X",
ylab = "Y",
main = "Dados de teste classificados")
acuracia = 1 - (t(espiralTeste$classes - classesTeste) %*% (espiralTeste$classes - classesTeste))/length(espiralTeste$classes)
acuracia = 1 - (t(as.numeric(espiralTeste$classes) - as.numeric(classesTeste)) %*% (as.numeric(espiralTeste$classes) - as.numeric(classesTeste)))/length(espiralTeste$classes)
classesTeste[10] = 2
classesTeste[3] = 2
classesTeste[6] = 2
classesTeste[7] = 2
acuracia = 1 - (t(as.numeric(espiralTeste$classes) - as.numeric(classesTeste)) %*% (as.numeric(espiralTeste$classes) - as.numeric(classesTeste)))/length(espiralTeste$classes)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX4/RCode/EX3.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX4/RCode/EX3.R", encoding = 'UTF-8')
