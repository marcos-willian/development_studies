acu = matrix(0,numSig,numTaus)
err = matrix(0,numSig,numTaus)
k = 0
k = k+1
l = 0
l = l+1
#Começa as interações
set.seed(0)
i = 1
tau = 0
sig = 0
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = tau)
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = tau)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = tau)
tau = 0.01
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = tau)
install.packages(c("cli", "curl", "fields", "Rcpp", "spam", "stringi"))
taus = 0
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
taus = 0.1
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
rm(list = ls())
library("kernlab")
library("mlbench")
library("plot3D")
library(caTools) #Função sample.split
data(Glass)
#Prepara variàveis
levels = levels(Glass$Type)
#Começa as interações
set.seed(0)
taus = 0.01
sig = 0.5
i = 1
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
for( i in 1:10){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
rm(list = ls())
library("kernlab")
library("mlbench")
library("plot3D")
library(caTools) #Função sample.split
data(Glass)
#Prepara variàveis
levels = levels(Glass$Type)
vetorAcuracia<- c()
vetorErro<- c()
#Começa as interações
set.seed(0)
for( i in 1:10){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
taus = 0
sig = 0.5
for( i in 1:10){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
= ls())
library("kernlab")
library("mlbench")
library("plot3D")
library(caTools) #Função sample.split
data(Glass)
#Prepara variàveis
levels = levels(Glass$Type)
vetorAcuracia<- c()
vetorErro<- c()
sig = 0.5
#Começa as interações
set.seed(0)
taus = 0.1
for( i in 1:1){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
sig = 0.1
for( i in 1:1){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
taus = 0.01
for( i in 1:1){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
taus = 0
for( i in 1:1){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
sig = 0
for( i in 1:1){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
length(seqTau)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
sig = 0.001
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
sig  = 0
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
sig = 0.001
tau = 0
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
length(seqSig)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
seqTau = seq(from = 0.01, to = 1, length.out = 10)
as.character(seqTau)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
length(seqSig)
source("C:/Users/marki/OneDrive - Universidade Federal de Minas Gerais/Livros_e_Faculdade/Reconhecimento de padrões/EX6/RCode/EX6.R", encoding = 'UTF-8')
rm(list = ls())
library("kernlab")
library("mlbench")
library("plot3D")
library(caTools) #Função sample.split
data(Glass)
#Prepara variàveis
levels = levels(Glass$Type)
vetorAcuracia<- c()
vetorErro<- c()
tau = 0.4111111111111
sig = 0.12222222222222
#Começa as interações
set.seed(0)
for( i in 1:10){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
rm(list = ls())
library("kernlab")
library("mlbench")
library("plot3D")
library(caTools) #Função sample.split
data(Glass)
levels = levels(Glass$Type)
vetorAcuracia<- c()
vetorErro<- c()
taus = 0.4111111111111
sig = 0.12222222222222
#Começa as interações
set.seed(0)
for( i in 1:10){
#Separar dados de teste e dados de treino
porcentagemTreino = c()
porcentagemTeste = c()
for(j in 1:length(levels)){
#Seleciona aleatoriamente 80% das amostras e respostas treino de cada tipo
#Os 30% restantes são para teste do modelo
dadosClasseN = Glass[Glass$Type == levels[j],]
sampleTreino = sample.split(dadosClasseN$Type, 0.8)
porcentagemTreino = rbind(porcentagemTreino, dadosClasseN[sampleTreino,])
porcentagemTeste = rbind(porcentagemTeste, dadosClasseN[!sampleTreino,])
}
#Treinamento modelo
lssvmTreinamento = lssvm(as.matrix(porcentagemTreino[, 1:9]),
porcentagemTreino$Type,
type = "classification",
kernel = "rbfdot",
kpar = list(sigma = sig),
tau = taus)
#Teste do modelo
#Classifica amostras
classesTeste = predict(lssvmTreinamento,
as.matrix(porcentagemTeste[, 1:9]),
type = "response",
coupler = "minpair")
vetorAcuracia[i] = sum(as.numeric(porcentagemTeste$Type == classesTeste))/length(porcentagemTeste$Type)
vetorErro[i] = error(lssvmTreinamento)
}
listaRetorno <- list()
listaRetorno$AcuraciaMedia <-  mean(vetorAcuracia)
listaRetorno$DesvioPadraoAcuracia <- sd(vetorAcuracia)
listaRetorno$ErroMedio <- mean(vetorErro)
print(listaRetorno)
